{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_model(X, Y, units=512):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_and_process_text(filename):\n",
    "    raw_text = open(filename).read().lower()\n",
    "    translation_table = dict.fromkeys(map(ord, '\\n\\r\\\"\\'()&$*-0123456789:;[]_`'), ' ')\n",
    "    raw_text = raw_text.translate(translation_table)\n",
    "    translation_table = dict.fromkeys(map(ord, '?!'), '.')\n",
    "    raw_text = raw_text.translate(translation_table)\n",
    "    raw_text = \" \".join(raw_text.split())\n",
    "    letters = sorted(list(set(raw_text)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(letters))\n",
    "    one_hot = np_utils.to_categorical([char_to_int[i] for i in letters]).tolist()\n",
    "    list_sentences = filter(None, raw_text.split(\".\"))\n",
    "    return one_hot, char_to_int, letters, list(map(lambda x: x + \".\", list_sentences))\n",
    "\n",
    "\n",
    "def create_dataset(one_hot, char_to_int, letters, list_sentences, seq_length):\n",
    "    dataX = list()\n",
    "    dataY = list()\n",
    "    for sentence in list_sentences:\n",
    "        for i in range(0, len(sentence) - seq_length):\n",
    "            seq_in = sentence[i:i + seq_length]\n",
    "            seq_out = sentence[i + seq_length]\n",
    "            dataX.append([one_hot[char_to_int[char]] for char in seq_in])\n",
    "            dataY.append(one_hot[char_to_int[seq_out]])\n",
    "    print(\"Total Vocab: \", len(letters))\n",
    "    print(\"Total Sequents: \", len(dataX))\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "def run_model(model, X, Y, path, epochs=10):\n",
    "    filepath = path + \"-weights.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit(X, Y, epochs=epochs, batch_size=64, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "def load_model(filename, model):\n",
    "    model.load_weights(filename)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def LSTM_gen(string, seq_length, letters, one_hot, char_to_int, model, max_len=1000):\n",
    "    if seq_length >= len(string):\n",
    "        print(\"Cannot predict(too short init string)\")\n",
    "        return string\n",
    "    last_string = string[-seq_length:]\n",
    "    current_window = [one_hot[char_to_int[ch]] for ch in last_string]\n",
    "    while True:\n",
    "        x = np.array([current_window])\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = letters[index]\n",
    "        string += result\n",
    "        if(result == '.') or (len(string) > max_len):\n",
    "            return string\n",
    "        current_window.append(one_hot[index])\n",
    "        current_window = current_window[1:len(current_window)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "seq_length = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocab:  29\n",
      "Total Sequents:  107966\n",
      "[' ', ',', '.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "one_hot, char_to_int, letters, list_sentences = read_and_process_text(\"data/alice_in_wonderland.txt\")\n",
    "\n",
    "[X, Y] = create_dataset(one_hot, char_to_int, letters, list_sentences, seq_length)\n",
    "del list_sentences\n",
    "print(letters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 512)               1110016   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 29)                14877     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,124,893\n",
      "Trainable params: 1,124,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(X, Y)\n",
    "load_model(\"runs/\" + str(seq_length) + \"-weights.hdf5\", model)\n",
    "# run_model(model, X, Y, \"runs/\" + str(seq_length), 1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def print_gen(string):\n",
    "    gen_string = LSTM_gen(string, seq_length, letters, one_hot, char_to_int, model)\n",
    "    print(gen_string)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in another moment down went alice after it, never once considering how in the world she was to get out again.\n"
     ]
    }
   ],
   "source": [
    "print_gen(\"in another moment down went alice after it\")# never once considering how in the world she was to get out again."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she was close behind it when she turned the corner, but the rabbit was no longer to be seen she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof.\n"
     ]
    }
   ],
   "source": [
    "print_gen(\"she was close behind it when she turned the corner,\")#but the rabbit was no longer to be seen:  she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she has mastered machine learning to the king, and the hatter hurriedly left the court, without even waiting to put his shoes on.\n"
     ]
    }
   ],
   "source": [
    "print_gen(\"she has mastered machine learning\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will eat this plunger for world peace with the white rabbit cried out, silence in the court.\n"
     ]
    }
   ],
   "source": [
    "print_gen(\"i will eat this plunger for world peace\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def accuracy(X, Y, model):\n",
    "    pred = model.predict(X)\n",
    "    pred = list(map(lambda x: np.argmax(x), pred))\n",
    "    real = list(map(lambda x: np.argmax(x), Y))\n",
    "    return accuracy_score(real, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926458329474094\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(X, Y, model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}